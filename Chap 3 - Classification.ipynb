{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8ce9425",
   "metadata": {},
   "source": [
    "# 1. MINST classifier with 97% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "118b3b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "\n",
    "mnist = fetch_openml('mnist_784',version = 1, as_frame = False)\n",
    "mnist.keys()\n",
    "X,y = mnist['data'], mnist['target']\n",
    "X_train = X[:60000]\n",
    "y_train = y[:60000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "974ecef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "kNN = KNeighborsClassifier(n_neighbors = 4, weights = \"distance\")\n",
    "model = kNN.fit(X_train,y_train)\n",
    "y_train_pred = model.predict(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e076d2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "a = precision_score(y_train,y_train_pred, average = \"weighted\")\n",
    "b = recall_score(y_train,y_train_pred, average = \"weighted\")\n",
    "c = f1_score(y_train,y_train_pred, average = \"weighted\")\n",
    "print(a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6465d9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X[60000:]\n",
    "y_test = y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "755ca377",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9715166824529755 0.9714 0.9713597782738583\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "d = precision_score(y_test,y_test_pred, average = \"weighted\")\n",
    "e = recall_score(y_test,y_test_pred, average = \"weighted\")\n",
    "f = f1_score(y_test,y_test_pred, average = \"weighted\")\n",
    "print(d,e,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31382810",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END ....n_neighbors=3, weights=uniform;, score=0.972 total time=  19.7s\n",
      "[CV 2/5] END ....n_neighbors=3, weights=uniform;, score=0.971 total time=  19.6s\n",
      "[CV 3/5] END ....n_neighbors=3, weights=uniform;, score=0.969 total time=  21.2s\n",
      "[CV 4/5] END ....n_neighbors=3, weights=uniform;, score=0.969 total time=  23.0s\n",
      "[CV 5/5] END ....n_neighbors=3, weights=uniform;, score=0.970 total time=  21.9s\n",
      "[CV 1/5] END ...n_neighbors=3, weights=distance;, score=0.972 total time=  18.8s\n",
      "[CV 2/5] END ...n_neighbors=3, weights=distance;, score=0.972 total time=  18.4s\n",
      "[CV 3/5] END ...n_neighbors=3, weights=distance;, score=0.970 total time=  18.8s\n",
      "[CV 4/5] END ...n_neighbors=3, weights=distance;, score=0.970 total time=  18.9s\n",
      "[CV 5/5] END ...n_neighbors=3, weights=distance;, score=0.971 total time=  20.9s\n",
      "[CV 1/5] END ....n_neighbors=4, weights=uniform;, score=0.969 total time=  20.5s\n",
      "[CV 2/5] END ....n_neighbors=4, weights=uniform;, score=0.968 total time=  19.0s\n",
      "[CV 3/5] END ....n_neighbors=4, weights=uniform;, score=0.968 total time=  20.7s\n",
      "[CV 4/5] END ....n_neighbors=4, weights=uniform;, score=0.967 total time=  22.3s\n",
      "[CV 5/5] END ....n_neighbors=4, weights=uniform;, score=0.970 total time=  21.0s\n",
      "[CV 1/5] END ...n_neighbors=4, weights=distance;, score=0.973 total time=  19.5s\n",
      "[CV 2/5] END ...n_neighbors=4, weights=distance;, score=0.972 total time=  20.8s\n",
      "[CV 3/5] END ...n_neighbors=4, weights=distance;, score=0.970 total time=  18.8s\n",
      "[CV 4/5] END ...n_neighbors=4, weights=distance;, score=0.971 total time=  19.7s\n",
      "[CV 5/5] END ...n_neighbors=4, weights=distance;, score=0.972 total time=  18.3s\n",
      "[CV 1/5] END ....n_neighbors=5, weights=uniform;, score=0.970 total time=  19.4s\n",
      "[CV 2/5] END ....n_neighbors=5, weights=uniform;, score=0.970 total time=  19.7s\n",
      "[CV 3/5] END ....n_neighbors=5, weights=uniform;, score=0.969 total time=  19.5s\n",
      "[CV 4/5] END ....n_neighbors=5, weights=uniform;, score=0.968 total time=  19.9s\n",
      "[CV 5/5] END ....n_neighbors=5, weights=uniform;, score=0.969 total time=  19.4s\n",
      "[CV 1/5] END ...n_neighbors=5, weights=distance;, score=0.970 total time=  18.5s\n",
      "[CV 2/5] END ...n_neighbors=5, weights=distance;, score=0.971 total time=  18.6s\n",
      "[CV 3/5] END ...n_neighbors=5, weights=distance;, score=0.970 total time=  18.6s\n",
      "[CV 4/5] END ...n_neighbors=5, weights=distance;, score=0.969 total time=  18.5s\n",
      "[CV 5/5] END ...n_neighbors=5, weights=distance;, score=0.971 total time=  17.6s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid=[{&#x27;n_neighbors&#x27;: [3, 4, 5],\n",
       "                          &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]}],\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid=[{&#x27;n_neighbors&#x27;: [3, 4, 5],\n",
       "                          &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]}],\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid=[{'n_neighbors': [3, 4, 5],\n",
       "                          'weights': ['uniform', 'distance']}],\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "KNN = KNeighborsClassifier()\n",
    "param_grid = [\n",
    "                {'weights': ['uniform','distance'],'n_neighbors':[3,4,5]}\n",
    "]\n",
    "grid_search = GridSearchCV(KNN, param_grid,cv = 5, verbose = 3)\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d8768a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 4, 'weights': 'distance'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174756a1",
   "metadata": {},
   "source": [
    "# 2.Data Augumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6106ca2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TAMIL SELVAN\\AppData\\Local\\Temp\\ipykernel_7304\\2468852759.py:1: DeprecationWarning: Please use `shift` from the `scipy.ndimage` namespace, the `scipy.ndimage.interpolation` namespace is deprecated.\n",
      "  from scipy.ndimage.interpolation import shift\n"
     ]
    }
   ],
   "source": [
    "from scipy.ndimage.interpolation import shift\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4612c4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_image(image, dx, dy):\n",
    "    image = image.reshape((28,28))\n",
    "    shifted_image = shift(image, [dx,dy], cval=0, mode='constant')\n",
    "    return shifted_image.reshape([-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "875e9cb8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1922140d400>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = X_train[59999]\n",
    "\n",
    "plt.imshow(image.reshape(28,28), interpolation = 'nearest', cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ca25cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_augumented = [image for image in X_train]\n",
    "y_train_augumented = [image for image in y_train]\n",
    "\n",
    "for dy, dx in ((1,0),(-1,0),(0,1),(0,-1)):\n",
    "    for image, label in zip(X_train, y_train):\n",
    "        X_train_augumented.append(shift_image(image, dx, dy))\n",
    "        y_train_augumented.append(label)\n",
    "X_train_augumented = np.array(X_train_augumented)\n",
    "y_train_augumented = np.array(y_train_augumented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c046c43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([255949, 281114, 242637, ..., 239405, 119538, 199139])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffle_idx = np.random.permutation(len(X_train_augumented))\n",
    "X_train_augumented = X_train_augumented[shuffle_idx]\n",
    "y_train_augumented = y_train_augumented[shuffle_idx]\n",
    "shuffle_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f236c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=4, weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=4, weights=&#x27;distance&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=4, weights='distance')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier(weights = 'distance', n_neighbors = 4)\n",
    "knn_clf.fit(X_train_augumented, y_train_augumented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edaa36d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test = y_test.reshape(-1)\n",
    "y_pred = knn_clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "991bea85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9763"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45562bd6",
   "metadata": {},
   "source": [
    "# Titanic classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce6c4728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#load dataset\n",
    "train_data = pd.read_csv(\"G:/MLbook/Titanic Kaggle/train.csv\")\n",
    "test_data = pd.read_csv(\"G:/MLbook/Titanic Kaggle/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "977457d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy = \"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy = \"most_frequent\")),\n",
    "    (\"cat_encoder\", OneHotEncoder(sparse = False))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "781c97b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attribs = [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "cat_attribs = [\"Pclass\", \"Sex\", \"Embarked\"]\n",
    "\n",
    "preprocess_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", cat_pipeline, cat_attribs),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "147eb229",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocess_pipeline.fit_transform(\n",
    "          train_data[num_attribs + cat_attribs])\n",
    "y_train = train_data[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e81caf83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_features=4, n_estimators=119, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_features=4, n_estimators=119, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_features=4, n_estimators=119, random_state=42)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_clf = RandomForestClassifier(max_features = 4, n_estimators = 119, random_state = 42)\n",
    "forest_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48ee45d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9797979797979798"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_train_pred = forest_clf.predict(X_train)\n",
    "accuracy_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98e4e234",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = preprocess_pipeline.fit_transform(\n",
    "         test_data[num_attribs+cat_attribs])\n",
    "y_pred = forest_clf.predict(X_test)\n",
    "\n",
    "handson_submission = pd.DataFrame()\n",
    "handson_submission['PassengerId'] = test_data['PassengerId']\n",
    "handson_submission['Survived'] = y_pred.astype('int64')\n",
    "handson_submission.to_csv('handson_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5f19f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8149063670411983"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "forest_scores = cross_val_score(forest_clf, X_train,y_train, cv = 10)\n",
    "forest_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "596a173c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV 1/5] END ..max_features=4, n_estimators=151;, score=0.799 total time=   0.5s\n",
      "[CV 2/5] END ..max_features=4, n_estimators=151;, score=0.815 total time=   0.5s\n",
      "[CV 3/5] END ..max_features=4, n_estimators=151;, score=0.848 total time=   0.5s\n",
      "[CV 4/5] END ..max_features=4, n_estimators=151;, score=0.775 total time=   0.5s\n",
      "[CV 5/5] END ..max_features=4, n_estimators=151;, score=0.854 total time=   0.5s\n",
      "[CV 1/5] END ...max_features=4, n_estimators=10;, score=0.788 total time=   0.0s\n",
      "[CV 2/5] END ...max_features=4, n_estimators=10;, score=0.798 total time=   0.0s\n",
      "[CV 3/5] END ...max_features=4, n_estimators=10;, score=0.843 total time=   0.0s\n",
      "[CV 4/5] END ...max_features=4, n_estimators=10;, score=0.798 total time=   0.0s\n",
      "[CV 5/5] END ...max_features=4, n_estimators=10;, score=0.820 total time=   0.0s\n",
      "[CV 1/5] END ..max_features=4, n_estimators=133;, score=0.804 total time=   0.4s\n",
      "[CV 2/5] END ..max_features=4, n_estimators=133;, score=0.815 total time=   0.4s\n",
      "[CV 3/5] END ..max_features=4, n_estimators=133;, score=0.860 total time=   0.5s\n",
      "[CV 4/5] END ..max_features=4, n_estimators=133;, score=0.775 total time=   0.5s\n",
      "[CV 5/5] END ..max_features=4, n_estimators=133;, score=0.854 total time=   0.5s\n",
      "[CV 1/5] END ...max_features=4, n_estimators=46;, score=0.782 total time=   0.1s\n",
      "[CV 2/5] END ...max_features=4, n_estimators=46;, score=0.815 total time=   0.1s\n",
      "[CV 3/5] END ...max_features=4, n_estimators=46;, score=0.837 total time=   0.1s\n",
      "[CV 4/5] END ...max_features=4, n_estimators=46;, score=0.781 total time=   0.0s\n",
      "[CV 5/5] END ...max_features=4, n_estimators=46;, score=0.837 total time=   0.1s\n",
      "[CV 1/5] END ..max_features=3, n_estimators=163;, score=0.765 total time=   0.5s\n",
      "[CV 2/5] END ..max_features=3, n_estimators=163;, score=0.792 total time=   0.6s\n",
      "[CV 3/5] END ..max_features=3, n_estimators=163;, score=0.843 total time=   0.6s\n",
      "[CV 4/5] END ..max_features=3, n_estimators=163;, score=0.781 total time=   0.6s\n",
      "[CV 5/5] END ..max_features=3, n_estimators=163;, score=0.826 total time=   0.6s\n",
      "[CV 1/5] END ...max_features=3, n_estimators=95;, score=0.771 total time=   0.3s\n",
      "[CV 2/5] END ...max_features=3, n_estimators=95;, score=0.798 total time=   0.3s\n",
      "[CV 3/5] END ...max_features=3, n_estimators=95;, score=0.854 total time=   0.2s\n",
      "[CV 4/5] END ...max_features=3, n_estimators=95;, score=0.775 total time=   0.3s\n",
      "[CV 5/5] END ...max_features=3, n_estimators=95;, score=0.826 total time=   0.2s\n",
      "[CV 1/5] END ..max_features=4, n_estimators=166;, score=0.793 total time=   0.6s\n",
      "[CV 2/5] END ..max_features=4, n_estimators=166;, score=0.815 total time=   0.6s\n",
      "[CV 3/5] END ..max_features=4, n_estimators=166;, score=0.848 total time=   0.5s\n",
      "[CV 4/5] END ..max_features=4, n_estimators=166;, score=0.775 total time=   0.5s\n",
      "[CV 5/5] END ..max_features=4, n_estimators=166;, score=0.843 total time=   0.6s\n",
      "[CV 1/5] END ..max_features=3, n_estimators=190;, score=0.765 total time=   0.6s\n",
      "[CV 2/5] END ..max_features=3, n_estimators=190;, score=0.798 total time=   0.7s\n",
      "[CV 3/5] END ..max_features=3, n_estimators=190;, score=0.843 total time=   0.6s\n",
      "[CV 4/5] END ..max_features=3, n_estimators=190;, score=0.781 total time=   0.6s\n",
      "[CV 5/5] END ..max_features=3, n_estimators=190;, score=0.826 total time=   0.6s\n",
      "[CV 1/5] END ...max_features=3, n_estimators=25;, score=0.765 total time=   0.0s\n",
      "[CV 2/5] END ...max_features=3, n_estimators=25;, score=0.792 total time=   0.0s\n",
      "[CV 3/5] END ...max_features=3, n_estimators=25;, score=0.843 total time=   0.1s\n",
      "[CV 4/5] END ...max_features=3, n_estimators=25;, score=0.781 total time=   0.0s\n",
      "[CV 5/5] END ...max_features=3, n_estimators=25;, score=0.843 total time=   0.0s\n",
      "[CV 1/5] END ...max_features=4, n_estimators=87;, score=0.799 total time=   0.1s\n",
      "[CV 2/5] END ...max_features=4, n_estimators=87;, score=0.815 total time=   0.3s\n",
      "[CV 3/5] END ...max_features=4, n_estimators=87;, score=0.843 total time=   0.2s\n",
      "[CV 4/5] END ...max_features=4, n_estimators=87;, score=0.775 total time=   0.3s\n",
      "[CV 5/5] END ...max_features=4, n_estimators=87;, score=0.843 total time=   0.3s\n",
      "[CV 1/5] END ..max_features=4, n_estimators=166;, score=0.793 total time=   0.6s\n",
      "[CV 2/5] END ..max_features=4, n_estimators=166;, score=0.815 total time=   0.6s\n",
      "[CV 3/5] END ..max_features=4, n_estimators=166;, score=0.848 total time=   0.6s\n",
      "[CV 4/5] END ..max_features=4, n_estimators=166;, score=0.775 total time=   0.6s\n",
      "[CV 5/5] END ..max_features=4, n_estimators=166;, score=0.843 total time=   0.7s\n",
      "[CV 1/5] END ...max_features=4, n_estimators=49;, score=0.788 total time=   0.1s\n",
      "[CV 2/5] END ...max_features=4, n_estimators=49;, score=0.815 total time=   0.1s\n",
      "[CV 3/5] END ...max_features=4, n_estimators=49;, score=0.837 total time=   0.2s\n",
      "[CV 4/5] END ...max_features=4, n_estimators=49;, score=0.781 total time=   0.1s\n",
      "[CV 5/5] END ...max_features=4, n_estimators=49;, score=0.837 total time=   0.0s\n",
      "[CV 1/5] END ..max_features=3, n_estimators=137;, score=0.765 total time=   0.4s\n",
      "[CV 2/5] END ..max_features=3, n_estimators=137;, score=0.798 total time=   0.5s\n",
      "[CV 3/5] END ..max_features=3, n_estimators=137;, score=0.848 total time=   0.4s\n",
      "[CV 4/5] END ..max_features=3, n_estimators=137;, score=0.775 total time=   0.4s\n",
      "[CV 5/5] END ..max_features=3, n_estimators=137;, score=0.826 total time=   0.4s\n",
      "[CV 1/5] END ..max_features=4, n_estimators=182;, score=0.799 total time=   0.7s\n",
      "[CV 2/5] END ..max_features=4, n_estimators=182;, score=0.815 total time=   0.7s\n",
      "[CV 3/5] END ..max_features=4, n_estimators=182;, score=0.848 total time=   0.6s\n",
      "[CV 4/5] END ..max_features=4, n_estimators=182;, score=0.775 total time=   0.6s\n",
      "[CV 5/5] END ..max_features=4, n_estimators=182;, score=0.848 total time=   0.5s\n",
      "[CV 1/5] END ...max_features=4, n_estimators=50;, score=0.777 total time=   0.0s\n",
      "[CV 2/5] END ...max_features=4, n_estimators=50;, score=0.815 total time=   0.1s\n",
      "[CV 3/5] END ...max_features=4, n_estimators=50;, score=0.837 total time=   0.1s\n",
      "[CV 4/5] END ...max_features=4, n_estimators=50;, score=0.781 total time=   0.0s\n",
      "[CV 5/5] END ...max_features=4, n_estimators=50;, score=0.837 total time=   0.2s\n",
      "[CV 1/5] END ..max_features=4, n_estimators=133;, score=0.804 total time=   0.3s\n",
      "[CV 2/5] END ..max_features=4, n_estimators=133;, score=0.815 total time=   0.4s\n",
      "[CV 3/5] END ..max_features=4, n_estimators=133;, score=0.860 total time=   0.4s\n",
      "[CV 4/5] END ..max_features=4, n_estimators=133;, score=0.775 total time=   0.4s\n",
      "[CV 5/5] END ..max_features=4, n_estimators=133;, score=0.854 total time=   0.6s\n",
      "[CV 1/5] END ..max_features=4, n_estimators=139;, score=0.804 total time=   0.6s\n",
      "[CV 2/5] END ..max_features=4, n_estimators=139;, score=0.815 total time=   0.6s\n",
      "[CV 3/5] END ..max_features=4, n_estimators=139;, score=0.860 total time=   0.6s\n",
      "[CV 4/5] END ..max_features=4, n_estimators=139;, score=0.775 total time=   0.4s\n",
      "[CV 5/5] END ..max_features=4, n_estimators=139;, score=0.854 total time=   0.4s\n",
      "[CV 1/5] END ..max_features=3, n_estimators=185;, score=0.760 total time=   0.9s\n",
      "[CV 2/5] END ..max_features=3, n_estimators=185;, score=0.798 total time=   0.7s\n",
      "[CV 3/5] END ..max_features=3, n_estimators=185;, score=0.843 total time=   0.6s\n",
      "[CV 4/5] END ..max_features=3, n_estimators=185;, score=0.775 total time=   0.6s\n",
      "[CV 5/5] END ..max_features=3, n_estimators=185;, score=0.826 total time=   0.6s\n",
      "[CV 1/5] END ..max_features=3, n_estimators=119;, score=0.771 total time=   0.4s\n",
      "[CV 2/5] END ..max_features=3, n_estimators=119;, score=0.803 total time=   0.3s\n",
      "[CV 3/5] END ..max_features=3, n_estimators=119;, score=0.854 total time=   0.3s\n",
      "[CV 4/5] END ..max_features=3, n_estimators=119;, score=0.781 total time=   0.3s\n",
      "[CV 5/5] END ..max_features=3, n_estimators=119;, score=0.820 total time=   0.3s\n",
      "[CV 1/5] END ..max_features=4, n_estimators=106;, score=0.799 total time=   0.2s\n",
      "[CV 2/5] END ..max_features=4, n_estimators=106;, score=0.815 total time=   0.3s\n",
      "[CV 3/5] END ..max_features=4, n_estimators=106;, score=0.848 total time=   0.2s\n",
      "[CV 4/5] END ..max_features=4, n_estimators=106;, score=0.781 total time=   0.3s\n",
      "[CV 5/5] END ..max_features=4, n_estimators=106;, score=0.843 total time=   0.3s\n",
      "[CV 1/5] END ..max_features=3, n_estimators=131;, score=0.771 total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..max_features=3, n_estimators=131;, score=0.798 total time=   0.3s\n",
      "[CV 3/5] END ..max_features=3, n_estimators=131;, score=0.848 total time=   0.4s\n",
      "[CV 4/5] END ..max_features=3, n_estimators=131;, score=0.781 total time=   0.4s\n",
      "[CV 5/5] END ..max_features=3, n_estimators=131;, score=0.826 total time=   0.4s\n",
      "[CV 1/5] END ..max_features=4, n_estimators=166;, score=0.793 total time=   0.5s\n",
      "[CV 2/5] END ..max_features=4, n_estimators=166;, score=0.815 total time=   0.4s\n",
      "[CV 3/5] END ..max_features=4, n_estimators=166;, score=0.848 total time=   0.5s\n",
      "[CV 4/5] END ..max_features=4, n_estimators=166;, score=0.775 total time=   0.5s\n",
      "[CV 5/5] END ..max_features=4, n_estimators=166;, score=0.843 total time=   0.5s\n",
      "[CV 1/5] END ...max_features=4, n_estimators=52;, score=0.782 total time=   0.0s\n",
      "[CV 2/5] END ...max_features=4, n_estimators=52;, score=0.815 total time=   0.1s\n",
      "[CV 3/5] END ...max_features=4, n_estimators=52;, score=0.837 total time=   0.1s\n",
      "[CV 4/5] END ...max_features=4, n_estimators=52;, score=0.775 total time=   0.0s\n",
      "[CV 5/5] END ...max_features=4, n_estimators=52;, score=0.837 total time=   0.1s\n",
      "[CV 1/5] END ..max_features=3, n_estimators=109;, score=0.771 total time=   0.3s\n",
      "[CV 2/5] END ..max_features=3, n_estimators=109;, score=0.787 total time=   0.4s\n",
      "[CV 3/5] END ..max_features=3, n_estimators=109;, score=0.860 total time=   0.2s\n",
      "[CV 4/5] END ..max_features=3, n_estimators=109;, score=0.775 total time=   0.3s\n",
      "[CV 5/5] END ..max_features=3, n_estimators=109;, score=0.820 total time=   0.4s\n",
      "[CV 1/5] END ..max_features=3, n_estimators=195;, score=0.771 total time=   0.6s\n",
      "[CV 2/5] END ..max_features=3, n_estimators=195;, score=0.798 total time=   0.6s\n",
      "[CV 3/5] END ..max_features=3, n_estimators=195;, score=0.843 total time=   0.6s\n",
      "[CV 4/5] END ..max_features=3, n_estimators=195;, score=0.781 total time=   0.6s\n",
      "[CV 5/5] END ..max_features=3, n_estimators=195;, score=0.826 total time=   0.6s\n",
      "[CV 1/5] END ...max_features=3, n_estimators=50;, score=0.760 total time=   0.1s\n",
      "[CV 2/5] END ...max_features=3, n_estimators=50;, score=0.798 total time=   0.1s\n",
      "[CV 3/5] END ...max_features=3, n_estimators=50;, score=0.854 total time=   0.1s\n",
      "[CV 4/5] END ...max_features=3, n_estimators=50;, score=0.781 total time=   0.1s\n",
      "[CV 5/5] END ...max_features=3, n_estimators=50;, score=0.837 total time=   0.0s\n",
      "[CV 1/5] END ...max_features=3, n_estimators=90;, score=0.765 total time=   0.3s\n",
      "[CV 2/5] END ...max_features=3, n_estimators=90;, score=0.798 total time=   0.2s\n",
      "[CV 3/5] END ...max_features=3, n_estimators=90;, score=0.848 total time=   0.4s\n",
      "[CV 4/5] END ...max_features=3, n_estimators=90;, score=0.775 total time=   0.1s\n",
      "[CV 5/5] END ...max_features=3, n_estimators=90;, score=0.826 total time=   0.3s\n",
      "[CV 1/5] END ...max_features=3, n_estimators=45;, score=0.760 total time=   0.0s\n",
      "[CV 2/5] END ...max_features=3, n_estimators=45;, score=0.792 total time=   0.2s\n",
      "[CV 3/5] END ...max_features=3, n_estimators=45;, score=0.848 total time=   0.1s\n",
      "[CV 4/5] END ...max_features=3, n_estimators=45;, score=0.781 total time=   0.0s\n",
      "[CV 5/5] END ...max_features=3, n_estimators=45;, score=0.837 total time=   0.0s\n",
      "[CV 1/5] END ...max_features=3, n_estimators=71;, score=0.765 total time=   0.4s\n",
      "[CV 2/5] END ...max_features=3, n_estimators=71;, score=0.792 total time=   0.1s\n",
      "[CV 3/5] END ...max_features=3, n_estimators=71;, score=0.848 total time=   0.1s\n",
      "[CV 4/5] END ...max_features=3, n_estimators=71;, score=0.781 total time=   0.2s\n",
      "[CV 5/5] END ...max_features=3, n_estimators=71;, score=0.820 total time=   0.1s\n",
      "[CV 1/5] END ...max_features=3, n_estimators=48;, score=0.760 total time=   0.1s\n",
      "[CV 2/5] END ...max_features=3, n_estimators=48;, score=0.798 total time=   0.2s\n",
      "[CV 3/5] END ...max_features=3, n_estimators=48;, score=0.854 total time=   0.1s\n",
      "[CV 4/5] END ...max_features=3, n_estimators=48;, score=0.775 total time=   0.1s\n",
      "[CV 5/5] END ...max_features=3, n_estimators=48;, score=0.837 total time=   0.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=RandomForestClassifier(max_features=4,\n",
       "                                                    n_estimators=119,\n",
       "                                                    random_state=42),\n",
       "                   n_iter=30,\n",
       "                   param_distributions={&#x27;max_features&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x000001929DFD76D0&gt;,\n",
       "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x000001929DFD7F40&gt;},\n",
       "                   verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=RandomForestClassifier(max_features=4,\n",
       "                                                    n_estimators=119,\n",
       "                                                    random_state=42),\n",
       "                   n_iter=30,\n",
       "                   param_distributions={&#x27;max_features&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x000001929DFD76D0&gt;,\n",
       "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x000001929DFD7F40&gt;},\n",
       "                   verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_features=4, n_estimators=119, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_features=4, n_estimators=119, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=RandomForestClassifier(max_features=4,\n",
       "                                                    n_estimators=119,\n",
       "                                                    random_state=42),\n",
       "                   n_iter=30,\n",
       "                   param_distributions={'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001929DFD76D0>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001929DFD7F40>},\n",
       "                   verbose=3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distribs = {\n",
    "    'n_estimators' : randint(low = 1, high = 200),\n",
    "    'max_features' : randint(low = 3, high = 5)\n",
    "}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(forest_clf, param_distributions = param_distribs,\n",
    "                               n_iter = 30, cv = 5, verbose = 3)\n",
    "\n",
    "rnd_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9815a1db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 4, 'n_estimators': 133}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e196e496",
   "metadata": {},
   "source": [
    "# Spam Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88c783ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile \n",
    "import urllib.request\n",
    "\n",
    "DOWNLOAD_ROOT = \"http://spamassassin.apache.org/old/publiccorpus/\"\n",
    "HAM_URL = DOWNLOAD_ROOT + \"20030228_easy_ham.tar.bz2\"\n",
    "SPAM_URL = DOWNLOAD_ROOT + \"20030228_spam.tar.bz2\"\n",
    "SPAM_PATH = os.path.join(\"datasets\", \"spam\")\n",
    "\n",
    "def fetch_spam_data(ham_url = HAM_URL, spam_url = SPAM_URL, spam_path = SPAM_PATH):\n",
    "    if not os.path.isdir(spam_path):\n",
    "        os.makedirs(spam_path)\n",
    "    for filename, url in ((\"ham.tar.bz2\", ham_url), (\"spam.tar.bz2\", spam_url)):\n",
    "        path = os.path.join(spam_path, filename)\n",
    "        if not os.path.isfile(path):\n",
    "            urllib.request.urlretrieve(url, path)\n",
    "        tar_bz2_file = tarfile.open(path)\n",
    "        tar_bz2_file.extractall(path = spam_path)\n",
    "        tar_bz2_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a911df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_spam_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b2c5a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "HAM_DIR = os.path.join(SPAM_PATH, \"easy_ham\")\n",
    "SPAM_DIR = os.path.join(SPAM_PATH, \"spam\")\n",
    "\n",
    "ham_filenames = [name for name in sorted(os.listdir(HAM_DIR)) if len(name)>20]\n",
    "spam_filenames = [name for name in sorted(os.listdir(SPAM_DIR)) if len(name)>20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e5c6cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "len(ham_filenames)\n",
    "len(spam_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07ee3b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import email \n",
    "import email.policy\n",
    "\n",
    "def load_email(is_spam, filename, spam_path = SPAM_PATH):\n",
    "    directory = \"spam\" if is_spam else \"easy_ham\"\n",
    "    with open(os.path.join(spam_path, directory, filename), \"rb\") as f:\n",
    "        return email.parser.BytesParser(policy = email.policy.default).parse(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4c194b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_emails = [load_email(is_spam = False, filename = name) for name in ham_filenames]\n",
    "spam_emails = [load_email(is_spam = True, filename = name) for name in spam_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cab8cab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date:        Wed, 21 Aug 2002 10:54:46 -0500\n",
      "    From:        Chris Garrigues <cwg-dated-1030377287.06fa6d@DeepEddy.Com>\n",
      "    Message-ID:  <1029945287.4797.TMDA@deepeddy.vircio.com>\n",
      "\n",
      "\n",
      "  | I can't reproduce this error.\n",
      "\n",
      "For me it is very repeatable... (like every time, without fail).\n",
      "\n",
      "This is the debug log of the pick happening ...\n",
      "\n",
      "18:19:03 Pick_It {exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace} {4852-4852 -sequence mercury}\n",
      "18:19:03 exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace 4852-4852 -sequence mercury\n",
      "18:19:04 Ftoc_PickMsgs {{1 hit}}\n",
      "18:19:04 Marking 1 hits\n",
      "18:19:04 tkerror: syntax error in expression \"int ...\n",
      "\n",
      "Note, if I run the pick command by hand ...\n",
      "\n",
      "delta$ pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace  4852-4852 -sequence mercury\n",
      "1 hit\n",
      "\n",
      "That's where the \"1 hit\" comes from (obviously).  The version of nmh I'm\n",
      "using is ...\n",
      "\n",
      "delta$ pick -version\n",
      "pick -- nmh-1.0.4 [compiled on fuchsia.cs.mu.OZ.AU at Sun Mar 17 14:55:56 ICT 2002]\n",
      "\n",
      "And the relevant part of my .mh_profile ...\n",
      "\n",
      "delta$ mhparam pick\n",
      "-seq sel -list\n",
      "\n",
      "\n",
      "Since the pick command works, the sequence (actually, both of them, the\n",
      "one that's explicit on the command line, from the search popup, and the\n",
      "one that comes from .mh_profile) do get created.\n",
      "\n",
      "kre\n",
      "\n",
      "ps: this is still using the version of the code form a day ago, I haven't\n",
      "been able to reach the cvs repository today (local routing issue I think).\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________\n",
      "Exmh-workers mailing list\n",
      "Exmh-workers@redhat.com\n",
      "https://listman.redhat.com/mailman/listinfo/exmh-workers\n"
     ]
    }
   ],
   "source": [
    "print(ham_emails[0].get_content().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47d498c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help wanted.  We are a 14 year old fortune 500 company, that is\n",
      "growing at a tremendous rate.  We are looking for individuals who\n",
      "want to work from home.\n",
      "\n",
      "This is an opportunity to make an excellent income.  No experience\n",
      "is required.  We will train you.\n",
      "\n",
      "So if you are looking to be employed from home with a career that has\n",
      "vast opportunities, then go:\n",
      "\n",
      "http://www.basetel.com/wealthnow\n",
      "\n",
      "We are looking for energetic and self motivated people.  If that is you\n",
      "than click on the link and fill out the form, and one of our\n",
      "employement specialist will contact you.\n",
      "\n",
      "To be removed from our link simple go to:\n",
      "\n",
      "http://www.basetel.com/remove.html\n",
      "\n",
      "\n",
      "4139vOLW7-758DoDY1425FRhM1-764SMFc8513fCsLl40\n"
     ]
    }
   ],
   "source": [
    "print(spam_emails[6].get_content().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bcb1e791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email_structure(email):\n",
    "    if isinstance(email, str):\n",
    "        #print('True')\n",
    "        return email\n",
    "    payload = email.get_payload()\n",
    "    #print(payload)\n",
    "    if isinstance(payload, list):\n",
    "        return \"multipart({})\".format(','.join([get_email_structure(sub_mail) for sub_mail in payload]))\n",
    "    else:\n",
    "        #print(email.get_content_type())\n",
    "        return email.get_content_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0b349c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def structures_counter(emails):\n",
    "    structures = Counter()\n",
    "    for email in emails:\n",
    "        structure = get_email_structure(email)\n",
    "        #print(structure)\n",
    "        structures[structure] += 1\n",
    "        #print(structures)\n",
    "    return structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "617a4733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text/plain', 3), ('multipart(text/plain,application/pgp-signature)', 1)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures_counter(ham_emails[13:17]).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4cefbf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = structures_counter(spam_emails).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05161312",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpamAssassin is hurting democracy!\n",
      "Owen\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "http://www.bayarea.com/mld/mercurynews/news/opinion/3900215.htm\n",
      "\n",
      "Internet can level the political playing field\n",
      "By Mike McCurry and Larry Purpuro\n",
      "\n",
      "NOT many months from now, people across the country will experience one \n",
      "of the great recurring features of American democracy. At shopping \n",
      "malls, on factory floors, at church socials and even on our front \n",
      "stoops, we will be approached by individuals who want to represent us in \n",
      "public office. While chances are high that we won't know them \n",
      "personally, they will walk up to us, offer a handshake and a flier and \n",
      "ask for our votes.\n",
      "\n",
      "Just as technology is affecting every other area of communication, it \n",
      "has begun to affect the way political candidates communicate with voters.\n",
      "\n",
      "In this year's GOP gubernatorial primary, California Secretary of State \n",
      "Bill Jones, who faced better-funded candidates, acquired the e-mail \n",
      "addresses of more than a million potential California voters and sent \n",
      "each an unsolicited e-mail asking for support.\n",
      "\n",
      "That day, he might have chosen any of the more traditional -- and more \n",
      "expensive -- methods of contacting voters, such as direct mail, radio \n",
      "spots or TV ads. But he spent only about 2 cents per message, instead of \n",
      "35 cents or more per message for direct mail or in another medium.\n",
      "\n",
      "Had Jones chosen direct mail, radio or TV, that communication would have \n",
      "been equally ``unsolicited,'' as defined in the e-mail world. Few voters \n",
      "would have ``opted in'' to receive campaign information from Jones \n",
      "through any of those channels.\n",
      "\n",
      "The response to Jones' e-mail effort, however, was swift and intense. He \n",
      "was lambasted by anti-spam advocates, and media coverage was almost \n",
      "entirely negative. To be fair, some of Jones' tactics could have been \n",
      "refined. He used a less-than-perfect list and no standard-practice \n",
      "``paid for'' disclaimer in the message.\n",
      "\n",
      "His detractors, however, attacked him not for his tactical miscues but \n",
      "because the e-mail was sent unsolicited. In fact, Jones' online campaign \n",
      "may have been his most visible asset. In an era of cynicism toward money \n",
      "in politics -- money typically spent on other unsolicited communication \n",
      "mediums -- Jones tried to level the playing field.\n",
      "\n",
      "No one likes commercial spam. It is irrelevant and untargeted and can be \n",
      "highly intrusive and even offensive. But as a sophisticated society, \n",
      "it's time to differentiate commercial spam from very different \n",
      "unsolicited e-mail sent by political candidates to voters.\n",
      "\n",
      "The debate is particularly relevant in light of legislation in Congress \n",
      "that would constitute the first federal law to directly address spam. We \n",
      "believe e-mail is no more intrusive than direct mail, telemarketing or \n",
      "TV advertising when it comes to politicians seeking to reach voters. A \n",
      "simple link in good e-mail campaigns allows recipients to opt out of \n",
      "future mailings. Direct mail takes at least a phone call or stamp to be \n",
      "taken off a list, and viewers must repeatedly endure TV ads.\n",
      "\n",
      "When a candidate lacks a large campaign war chest, he or she can use the \n",
      "Internet to provide constituents with information to better prepare them \n",
      "to perform their civic duty of casting educated votes. With more than 60 \n",
      "percent of all potential voters in this country possessing e-mail \n",
      "accounts, it makes sense that political candidates use this medium.\n",
      "\n",
      "Candidates might avoid some of the tactical problems encountered by the \n",
      "Jones campaign if they use the technologies available today that better \n",
      "ensure quality of e-mail lists and target content to specific recipient \n",
      "groups.\n",
      "\n",
      "But the broader point remains. When a political candidate sends a voter \n",
      "an e-mail, that recipient can choose to delete the message without \n",
      "opening it, unsubscribe from the list, read it or even reply and engage \n",
      "the sender. That choice should belong to the voter -- not to anti-spam \n",
      "advocates whose efforts are better focused on commercial e-mail. \n",
      "Political candidates should be free to communicate with voters as best \n",
      "they can, and let voters decide what to do with that information.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Mike McCurry, former press secretary for President Clinton, is CEO of an \n",
      "advocacy management and communications software company. Larry Purpuro, \n",
      "the former Republican National Committee deputy chief of staff, is \n",
      "founder and president of a political e-marketing firm. This was written \n",
      "for the Los Angeles Times. \n",
      "\n",
      "http://xent.com/mailman/listinfo/fork\n"
     ]
    }
   ],
   "source": [
    "print(ham_emails[14].get_content().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a114abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(ham_emails + spam_emails, dtype=object)\n",
    "y = np.array([0] * len(ham_emails) + [1] * len(spam_emails))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "76f1c8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from html import unescape\n",
    "\n",
    "def html_to_plain_text(html):\n",
    "    text = re.sub('<head.*?>.*?</head>', '', html, flags = re.M | re.S | re.I)\n",
    "    text = re.sub('<a\\s.*?>', 'HYPERLINK', text, flags = re.M | re.S | re.I)\n",
    "    text = re.sub('<.*?>', '', text, flags = re.M | re.S)\n",
    "    text = re.sub(r'(\\s*\\n)+','\\n', text, flags = re.M | re.S)\n",
    "    return unescape(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "702c0b7a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HTML><HEAD><TITLE></TITLE><META http-equiv=\"Content-Type\" content=\"text/html; charset=windows-1252\"><STYLE>A:link {TEX-DECORATION: none}A:active {TEXT-DECORATION: none}A:visited {TEXT-DECORATION: none}A:hover {COLOR: #0033ff; TEXT-DECORATION: underline}</STYLE><META content=\"MSHTML 6.00.2713.1100\" name=\"GENERATOR\"></HEAD>\n",
      "<BODY text=\"#000000\" vLink=\"#0033ff\" link=\"#0033ff\" bgColor=\"#CCCC99\"><TABLE borderColor=\"#660000\" cellSpacing=\"0\" cellPadding=\"0\" border=\"0\" width=\"100%\"><TR><TD bgColor=\"#CCCC99\" valign=\"top\" colspan=\"2\" height=\"27\">\n",
      "<font size=\"6\" face=\"Arial, Helvetica, sans-serif\" color=\"#660000\">\n",
      "<b>OTC</b></font></TD></TR><TR><TD height=\"2\" bgcolor=\"#6a694f\">\n",
      "<font size=\"5\" face=\"Times New Roman, Times, serif\" color=\"#FFFFFF\">\n",
      "<b>&nbsp;Newsletter</b></font></TD><TD height=\"2\" bgcolor=\"#6a694f\"><div align=\"right\"><font color=\"#FFFFFF\">\n",
      "<b>Discover Tomorrow's Winners&nbsp;</b></font></div></TD></TR><TR><TD height=\"25\" colspan=\"2\" bgcolor=\"#CCCC99\"><table width=\"100%\" border=\"0\" c  ...\n"
     ]
    }
   ],
   "source": [
    "html_spam_mails = [email for email in X_train[y_train == 1] if get_email_structure(email) == \"text/html\"]\n",
    "\n",
    "sample_html_spam = html_spam_mails[7]\n",
    "print(sample_html_spam.get_content().strip()[:1001], \" ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b5811a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OTC\n",
      " Newsletter\n",
      "Discover Tomorrow's Winners \n",
      "For Immediate Release\n",
      "Cal-Bay (Stock Symbol: CBYI)\n",
      "Watch for analyst \"Strong Buy Recommendations\" and several advisory newsletters picking CBYI.  CBYI has filed to be traded on the OTCBB, share prices historically INCREASE when companies get listed on this larger trading exchange. CBYI is trading around 25 cents and should skyrocket to $2.66 - $3.25 a share in the near future.\n",
      "Put CBYI on your watch list, acquire a position TODAY.\n",
      "REASONS TO INVEST IN CBYI\n",
      "A profitable company and is on track to beat ALL earnings estimates!\n",
      "One of the FASTEST growing distributors in environmental & safety equipment instruments.\n",
      "Excellent management team, several EXCLUSIVE contracts.  IMPRESSIVE client list including the U.S. Air Force, Anheuser-Busch, Chevron Refining and Mitsubishi Heavy Industries, GE-Energy & Environmental Research.\n",
      "RAPIDLY GROWING INDUSTRY\n",
      "Industry revenues exceed $900 million, estimates indicate that there could be as much as $25 billio ...\n"
     ]
    }
   ],
   "source": [
    "print(html_to_plain_text(sample_html_spam.get_content().strip())[:1001], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3f1743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_to_text(email):\n",
    "    html = None\n",
    "    #print(email.walk())\n",
    "    for part in email.walk():\n",
    "        ctype = part.get_content_type()\n",
    "        if not ctype in ('text/plain', 'text/html'):\n",
    "            continue\n",
    "        try:\n",
    "            content = part.get_content()\n",
    "        except:\n",
    "            content = str(part.get_payload())\n",
    "        if ctype == \"text/plain\":\n",
    "            return content\n",
    "        else:\n",
    "            html = content\n",
    "            #print(html)\n",
    "    if html:\n",
    "        return html_to_plain_text(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c645abe4",
   "metadata": {},
   "source": [
    "We go through every part of the mail and check if it is \"text/plain\" or \"text/html\". If even one part of the mail is \"text/html\", then the email will be passed to html_to_plain_text() and will be returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea9e92a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OTC\n",
      " Newsletter\n",
      "Discover Tomorrow's Winners \n",
      "For Immediate Release\n",
      "Cal-Bay (Stock Symbol: CBYI)\n",
      "Wat 000\n"
     ]
    }
   ],
   "source": [
    "print(email_to_text(sample_html_spam)[:100],\"000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f3aa79e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\tamil selvan\\.conda\\envs\\mlbook\\lib\\site-packages (3.7)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: click in c:\\users\\tamil selvan\\.conda\\envs\\mlbook\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\tamil selvan\\.conda\\envs\\mlbook\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: joblib in c:\\users\\tamil selvan\\.conda\\envs\\mlbook\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tamil selvan\\.conda\\envs\\mlbook\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\tamil selvan\\.conda\\envs\\mlbook\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "337e5f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computations => comput\n",
      "computed => comput\n",
      "computing => comput\n",
      "computation => comput\n",
      "compute => comput\n",
      "compulsive => compuls\n",
      "convergence => converg\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import nltk\n",
    "    \n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    for word in (\"Computations\", \"computed\", \"computing\", \"computation\", \"compute\", \"compulsive\", \"convergence\"):\n",
    "        print(word, \"=>\", stemmer.stem(word))\n",
    "except ImportError:\n",
    "    print(\" Error: Stemming requires the NLTK module\")\n",
    "    stemmer = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ea0b996",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: urlextract in c:\\users\\tamil selvan\\.conda\\envs\\mlbook\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: uritools in c:\\users\\tamil selvan\\.conda\\envs\\mlbook\\lib\\site-packages (from urlextract) (4.0.0)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\tamil selvan\\.conda\\envs\\mlbook\\lib\\site-packages (from urlextract) (2.5.2)\n",
      "Requirement already satisfied: idna in c:\\users\\tamil selvan\\.conda\\envs\\mlbook\\lib\\site-packages (from urlextract) (3.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\tamil selvan\\.conda\\envs\\mlbook\\lib\\site-packages (from urlextract) (3.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install urlextract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d7b08ec9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['github.com', 'https://www.youtube.com/watch?v=Y1Gndz4sNeE']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import urlextract\n",
    "    \n",
    "    url_extractor = urlextract.URLExtract()\n",
    "    print(url_extractor.find_urls(\"will it detect github.com and https://www.youtube.com/watch?v=Y1Gndz4sNeE\"))\n",
    "\n",
    "except ImportError:\n",
    "    print(\"Error: replacing URLs requires the urlextract module. \")\n",
    "    url_extractor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2063aed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class EmailToWordCounterTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strip_headers = True, lower_case = True, remove_punctuation = True,\n",
    "                replace_urls = True, replace_numbers = True, stemming = True):\n",
    "        self.strip_headers = strip_headers\n",
    "        self.lower_case = lower_case\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.replace_urls = replace_urls\n",
    "        self.replace_numbers = replace_numbers\n",
    "        self.stemming = stemming\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def transform(self, X, y = None):\n",
    "        X_transformed = []\n",
    "        for email in X:\n",
    "            text = email_to_text(email) or \"\"\n",
    "            if self.lower_case:\n",
    "                text = text.lower()\n",
    "            if self.replace_urls and url_extractor is not None:\n",
    "                urls = list(set(url_extractor.find_urls(text)))\n",
    "                urls.sort(key = lambda url: len(url), reverse = True)\n",
    "                for url in urls:\n",
    "                    text = text.replace(url, \"URL\")\n",
    "            if self.replace_numbers:\n",
    "                text = re.sub(r'\\d+(?:\\.\\d*)?(?:[eE][+-]?\\d+)?', 'NUMBER', text)\n",
    "            if self.remove_punctuation:\n",
    "                text = re.sub(r'\\W+', ' ', text, flags = re.M)\n",
    "            word_counts = Counter(text.split())\n",
    "            if self.stemming and stemmer is not None:\n",
    "                stemmed_word_counts = Counter()\n",
    "                for word, count in word_counts.items():\n",
    "                    stemmed_word = stemmer.stem(word)\n",
    "                    stemmed_word_counts[stemmed_word] += count\n",
    "                word_counts = stemmed_word_counts\n",
    "            X_transformed.append(word_counts)\n",
    "        return np.array(X_transformed)\n",
    "\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8bbaac75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 text/plain 218\n",
      "1 text/html 183\n",
      "2 multipart(text/plain,text/html) 45\n",
      "3 multipart(text/html) 20\n",
      "4 multipart(text/plain) 19\n",
      "5 multipart(multipart(text/html)) 5\n",
      "6 multipart(text/plain,image/jpeg) 3\n",
      "7 multipart(text/html,application/octet-stream) 2\n",
      "8 multipart(text/plain,application/octet-stream) 1\n",
      "9 multipart(text/html,text/plain) 1\n",
      "10 multipart(multipart(text/html),application/octet-stream,image/jpeg) 1\n",
      "11 multipart(multipart(text/plain,text/html),image/gif) 1\n",
      "12 multipart/alternative 1\n"
     ]
    }
   ],
   "source": [
    "X_few = X_train[3:5]\n",
    "X_few_wordcounts = EmailToWordCounterTransformer().fit_transform(X_few)\n",
    "for i, (w,n) in enumerate(t):\n",
    "    print(i,w,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "855c296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "class WordCounterToVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vocabulary_size = 1000):\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "    def fit(self, X, y = None):\n",
    "        total_counter = Counter()\n",
    "        for word_count in X:\n",
    "            for word, count in word_count.items():\n",
    "                total_counter[word] += min(count, 10)\n",
    "        most_common = total_counter.most_common()[:self.vocabulary_size]\n",
    "        self.vocabulary_ = { word: index+1 for index, (word, count) in enumerate(most_common)}\n",
    "        return self\n",
    "    def transform(self, X, y = None):\n",
    "        rows = []\n",
    "        cols = []\n",
    "        data = []\n",
    "        for row, word_count in enumerate(X):\n",
    "            for word, count in word_count.items():\n",
    "                rows.append(row)\n",
    "                cols.append(self.vocabulary_.get(word, 0))\n",
    "                data.append(count)\n",
    "        return csr_matrix((data, (rows, cols)), shape = (len(X), self.vocabulary_size+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dc41f4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49,  2,  6,  1,  0,  0,  2,  1,  1,  0,  2],\n",
       "       [79,  8,  2,  6,  5,  5,  2,  3,  3,  4,  1]], dtype=int32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transformer = WordCounterToVectorTransformer(vocabulary_size = 10)\n",
    "X_few_vectors = vocab_transformer.fit_transform(X_few_wordcounts)\n",
    "X_few_vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a486899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "preprocess_pipeline = Pipeline([\n",
    "    (\"email_to_wordcount\", EmailToWordCounterTransformer()),\n",
    "    (\"wordcount_to_vector\", WordCounterToVectorTransformer()),\n",
    "])\n",
    "\n",
    "X_train_transformed = preprocess_pipeline.fit_transform(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aecb3ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.981) total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.981) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.991) total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9845833333333333"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "log_clf =  LogisticRegression(solver = \"lbfgs\", max_iter = 1000, random_state = 42)\n",
    "score = cross_val_score(log_clf, X_train_transformed, y_train, cv = 3, verbose = 3)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5b12c5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 94.90%\n",
      "Recall: 97.89%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "X_test_transformed = preprocess_pipeline.transform(X_test)\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"lbfgs\", max_iter=1000, random_state=42)\n",
    "log_clf.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred = log_clf.predict(X_test_transformed)\n",
    "\n",
    "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred)))\n",
    "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dee61845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 94.90%\n",
      "Recall: 97.89%\n",
      "f1_score: 96.37%\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: {:.2f}%\".format(100*precision_score(y_test, y_pred)))\n",
    "print(\"Recall: {:.2f}%\".format(100*recall_score(y_test, y_pred)))\n",
    "print(\"f1_score: {:.2f}%\".format(100*f1_score(y_test, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

