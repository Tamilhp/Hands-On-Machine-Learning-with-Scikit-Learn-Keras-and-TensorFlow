{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f293ff8d",
   "metadata": {},
   "source": [
    "- This is a practice notebook. It differs slightly from the original implementation of the author, in that in exercise e), I added alpha dropout layer after every hidden layer but the author seem to add only at the end\n",
    "- Similarly, I didn't change the alpha dropout layer to MCdropout layer while predition\n",
    "- Same for f) as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7147ca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77482efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-08 10:46:47.281666: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-08 10:46:47.303412: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-08 10:46:47.694486: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c763c7",
   "metadata": {},
   "source": [
    "### Setting up a virtual GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbd2a577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical Devices 1 Logical Devices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-08 10:46:48.502323: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-08 10:46:48.523865: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-08 10:46:48.523929: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-08 10:46:48.525779: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-08 10:46:48.525842: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-08 10:46:48.525880: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-08 10:46:48.831541: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-08 10:46:48.831654: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-08 10:46:48.831695: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-08 10:46:48.831743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3072 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "# Creating a virtual GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict Tensorflow to allocate only 1 GB of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.set_logical_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.LogicalDeviceConfiguration(memory_limit=3072)])\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical Devices\", len(logical_gpus), \"Logical Devices\")\n",
    "    except RuntimError as e:\n",
    "        print(e)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d34e3c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b6de30",
   "metadata": {},
   "source": [
    "### Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86c9142",
   "metadata": {},
   "source": [
    "Practice training a Deep Neural Network on the CIFAR10 image Dataset\n",
    "\n",
    "- a) Build a DNN with 20 hiddden layers of 100 neuron each. Use He initialization and the ELU activation\n",
    "- b) Using Nadam optimization and early stopping, train the network on the CIFAR10 dataset. You can load it with keras.datasets.cifar10.load-data(). The Dataset is composed of 60000 32 * 32-pixel color images(50,000 for training and 10000 for testing) with 10 classes, so you'll need a softmax output layer with 10 neurons. Remember to search for the right learning rate each time you change the model's architecture or hyperparameters.\n",
    "- c) Now try adding Batch Normalization and compare the learning curves: Is it converging faster than before? Does it producre a better model? How does it affect the training speed?\n",
    "- d) Try replacing Batch Normalization with SELU and make the necessary adjustments to ensure the network self-normalzation(i.e., standardize the intput features, use LeCun normal initialization, make sure the DNN contains only a sequence of dense layers, etc.).\n",
    "- e) Try regularizing the model with alpha dropout. Then, without retraining your model, see if you can achieve better accuracy using MC Dropout.\n",
    "- f) Retrain your model using Icycle scheduling and see if it improves training speed and model accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b35b8b8",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c47728d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, Y_train_full), (x_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c2fa7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid = X_train_full[:45000]/255., X_train_full[45000:]/255.\n",
    "y_train, y_valid = Y_train_full[:45000], Y_train_full[45000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6695439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20fb5b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([keras.layers.Flatten(input_shape=(32, 32, 3)),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.Dense(units=10, activation=\"softmax\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ed4537",
   "metadata": {},
   "source": [
    "### b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1912ebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(patience=10)\n",
    "model_cp = keras.callbacks.ModelCheckpoint(\"my_cifar10_model.h5\")\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", \n",
    "              optimizer = keras.optimizers.experimental.Nadam(learning_rate=1e-3, beta_1=0.9, beta_2=0.999),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f281ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-08 10:46:51.644260: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-07-08 10:46:51.645959: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fce14ff9f70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-08 10:46:51.645971: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2023-07-08 10:46:51.649723: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-07-08 10:46:51.721058: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n",
      "2023-07-08 10:46:51.787278: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 9s 3ms/step - loss: 2.0478 - accuracy: 0.2431 - val_loss: 1.9764 - val_accuracy: 0.2692\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.8416 - accuracy: 0.3270 - val_loss: 1.8858 - val_accuracy: 0.3070\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.7749 - accuracy: 0.3568 - val_loss: 1.7629 - val_accuracy: 0.3508\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.7215 - accuracy: 0.3805 - val_loss: 1.7465 - val_accuracy: 0.3868\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.6847 - accuracy: 0.3946 - val_loss: 1.7451 - val_accuracy: 0.3876\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.6626 - accuracy: 0.4068 - val_loss: 1.7323 - val_accuracy: 0.3818\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.6302 - accuracy: 0.4181 - val_loss: 1.6424 - val_accuracy: 0.4282\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.7082 - accuracy: 0.3830 - val_loss: 1.8949 - val_accuracy: 0.3124\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.7579 - accuracy: 0.3592 - val_loss: 1.6778 - val_accuracy: 0.4026\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.6584 - accuracy: 0.4033 - val_loss: 1.6582 - val_accuracy: 0.4130\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.6092 - accuracy: 0.4223 - val_loss: 1.6309 - val_accuracy: 0.4306\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.5807 - accuracy: 0.4367 - val_loss: 1.6300 - val_accuracy: 0.4192\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.5598 - accuracy: 0.4407 - val_loss: 1.5973 - val_accuracy: 0.4448\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.5416 - accuracy: 0.4519 - val_loss: 1.6040 - val_accuracy: 0.4306\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.5363 - accuracy: 0.4519 - val_loss: 1.5612 - val_accuracy: 0.4506\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.5100 - accuracy: 0.4615 - val_loss: 1.5762 - val_accuracy: 0.4420\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 2.2926 - accuracy: 0.3360 - val_loss: 1.8602 - val_accuracy: 0.3018\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.7759 - accuracy: 0.3360 - val_loss: 1.7972 - val_accuracy: 0.3500\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.7615 - accuracy: 0.3529 - val_loss: 1.8360 - val_accuracy: 0.3110\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.7519 - accuracy: 0.3489 - val_loss: 1.7394 - val_accuracy: 0.3660\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.6743 - accuracy: 0.3864 - val_loss: 1.7132 - val_accuracy: 0.3788\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.6385 - accuracy: 0.4015 - val_loss: 1.9961 - val_accuracy: 0.3898\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.6264 - accuracy: 0.4056 - val_loss: 1.7127 - val_accuracy: 0.3866\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.5996 - accuracy: 0.4201 - val_loss: 1.6719 - val_accuracy: 0.3896\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.5878 - accuracy: 0.4222 - val_loss: 1.6271 - val_accuracy: 0.4138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd253f557e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for the training:  102.81397342681885\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "model.fit(x_train, y_train, epochs=100,\n",
    "         validation_data=(x_valid, y_valid),\n",
    "         callbacks=[early_stopping, model_cp])\n",
    "end = time.time()\n",
    "print(\"Time taken for the training: \",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b48f573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 881us/step - loss: 1.6271 - accuracy: 0.4138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.62712824344635, 0.4138000011444092]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_cifar10_model.h5\")\n",
    "model.evaluate(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bedadb",
   "metadata": {},
   "source": [
    "### c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d151c8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_batch_normalization = keras.models.Sequential([keras.layers.Flatten(input_shape=(32, 32, 3)),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.Dense(units=100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "                                keras.layers.BatchNormalization(),\n",
    "                                keras.layers.Dense(units=10, activation=\"softmax\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "724d1f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(patience=10)\n",
    "model_batch_normalization.compile(loss = \"sparse_categorical_crossentropy\", \n",
    "              optimizer = keras.optimizers.experimental.Nadam(learning_rate=1e-3, beta_1=0.9, beta_2=0.999),\n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9499addb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 18s 7ms/step - loss: 1.9009 - accuracy: 0.3152 - val_loss: 1.6930 - val_accuracy: 0.3968\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.7168 - accuracy: 0.3879 - val_loss: 1.6174 - val_accuracy: 0.4258\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.6534 - accuracy: 0.4134 - val_loss: 1.5491 - val_accuracy: 0.4476\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.5968 - accuracy: 0.4371 - val_loss: 1.5338 - val_accuracy: 0.4618\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.5509 - accuracy: 0.4497 - val_loss: 1.4596 - val_accuracy: 0.4874\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.5149 - accuracy: 0.4654 - val_loss: 1.4285 - val_accuracy: 0.5016\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.4817 - accuracy: 0.4782 - val_loss: 1.4596 - val_accuracy: 0.4778\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4429 - accuracy: 0.4943 - val_loss: 1.4164 - val_accuracy: 0.5052\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4168 - accuracy: 0.5013 - val_loss: 1.3824 - val_accuracy: 0.5050\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3916 - accuracy: 0.5088 - val_loss: 1.3745 - val_accuracy: 0.5182\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3671 - accuracy: 0.5212 - val_loss: 1.3677 - val_accuracy: 0.5182\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3427 - accuracy: 0.5282 - val_loss: 1.3988 - val_accuracy: 0.5150\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3260 - accuracy: 0.5360 - val_loss: 1.3673 - val_accuracy: 0.5254\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3088 - accuracy: 0.5452 - val_loss: 1.3483 - val_accuracy: 0.5228\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2824 - accuracy: 0.5509 - val_loss: 1.3592 - val_accuracy: 0.5330\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2702 - accuracy: 0.5560 - val_loss: 1.3707 - val_accuracy: 0.5174\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2507 - accuracy: 0.5637 - val_loss: 1.3533 - val_accuracy: 0.5302\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2308 - accuracy: 0.5708 - val_loss: 1.3650 - val_accuracy: 0.5248\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2154 - accuracy: 0.5733 - val_loss: 1.3867 - val_accuracy: 0.5268\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1933 - accuracy: 0.5817 - val_loss: 1.3561 - val_accuracy: 0.5304\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1900 - accuracy: 0.5849 - val_loss: 1.3664 - val_accuracy: 0.5214\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1774 - accuracy: 0.5878 - val_loss: 1.3591 - val_accuracy: 0.5376\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.1652 - accuracy: 0.5914 - val_loss: 1.3703 - val_accuracy: 0.5222\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.1448 - accuracy: 0.5996 - val_loss: 1.3532 - val_accuracy: 0.5302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd1fe1e6c50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to trian the model with BN:  237.58348441123962\n"
     ]
    }
   ],
   "source": [
    "start_BN = time.time()\n",
    "model_batch_normalization.fit(x_train, y_train, epochs=100,\n",
    "                             validation_data=(x_valid, y_valid),\n",
    "                             callbacks=[early_stopping, model_cp])\n",
    "end_BN = time.time()\n",
    "\n",
    "print(\"Time taken to trian the model with BN: \", end_BN-start_BN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ac549c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step - loss: 1.3532 - accuracy: 0.5302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3532238006591797, 0.5302000045776367]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_cifar10_model.h5\")\n",
    "model.evaluate(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e7f13b",
   "metadata": {},
   "source": [
    "### d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98a2e91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c37f8d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "training_samples, _, _, _ = x_train.shape\n",
    "valid_samples, _ , _, _ = x_valid.shape\n",
    "\n",
    "x_train_reshaped = x_train.reshape(training_samples, -1)\n",
    "x_valid_reshaped = x_valid.reshape(valid_samples, -1)\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train_reshaped)\n",
    "x_valid_scaled = scaler.fit_transform(x_valid_reshaped)\n",
    "\n",
    "x_train_standardized = x_train_scaled.reshape(x_train.shape)\n",
    "x_valid_standardized = x_valid_scaled.reshape(x_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51e2a3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selu = keras.models.Sequential([keras.layers.Flatten(input_shape=(32, 32, 3)),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                keras.layers.Dense(units=10, activation=\"softmax\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81815d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selu.compile(loss = \"sparse_categorical_crossentropy\",\n",
    "                   optimizer=keras.optimizers.experimental.Nadam(learning_rate=1e-3, beta_1=0.9, beta_2=0.999),\n",
    "                  metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fedc04f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 7s 3ms/step - loss: 1.9511 - accuracy: 0.2873 - val_loss: 1.8829 - val_accuracy: 0.3028\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.7697 - accuracy: 0.3529 - val_loss: 1.7943 - val_accuracy: 0.3806\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.6766 - accuracy: 0.3949 - val_loss: 1.6495 - val_accuracy: 0.4146\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.6178 - accuracy: 0.4184 - val_loss: 1.6445 - val_accuracy: 0.4202\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.5721 - accuracy: 0.4391 - val_loss: 1.6712 - val_accuracy: 0.4232\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.5316 - accuracy: 0.4548 - val_loss: 1.5965 - val_accuracy: 0.4332\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.6408 - accuracy: 0.4034 - val_loss: 1.6715 - val_accuracy: 0.3956\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.5256 - accuracy: 0.4483 - val_loss: 1.5791 - val_accuracy: 0.4492\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.4573 - accuracy: 0.4797 - val_loss: 1.6148 - val_accuracy: 0.4350\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.4250 - accuracy: 0.4910 - val_loss: 1.5230 - val_accuracy: 0.4696\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.3957 - accuracy: 0.5060 - val_loss: 1.5541 - val_accuracy: 0.4498\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.3652 - accuracy: 0.5156 - val_loss: 1.4921 - val_accuracy: 0.4728\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.3989 - accuracy: 0.5038 - val_loss: 1.5429 - val_accuracy: 0.4566\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.3584 - accuracy: 0.5156 - val_loss: 1.4972 - val_accuracy: 0.4688\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.3035 - accuracy: 0.5386 - val_loss: 1.4689 - val_accuracy: 0.4860\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.2780 - accuracy: 0.5462 - val_loss: 1.4706 - val_accuracy: 0.4860\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.3114 - accuracy: 0.5350 - val_loss: 1.5153 - val_accuracy: 0.4754\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.2426 - accuracy: 0.5633 - val_loss: 1.5003 - val_accuracy: 0.4966\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.2198 - accuracy: 0.5711 - val_loss: 1.5352 - val_accuracy: 0.4684\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.2027 - accuracy: 0.5767 - val_loss: 1.5007 - val_accuracy: 0.4910\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.1937 - accuracy: 0.5815 - val_loss: 1.5014 - val_accuracy: 0.4964\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.1708 - accuracy: 0.5877 - val_loss: 1.5335 - val_accuracy: 0.4872\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.1466 - accuracy: 0.5964 - val_loss: 1.4894 - val_accuracy: 0.5042\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.1297 - accuracy: 0.6051 - val_loss: 1.5144 - val_accuracy: 0.4914\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.1094 - accuracy: 0.6105 - val_loss: 1.4906 - val_accuracy: 0.4896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd11ec0b190>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for training the model_selu:  100.98614358901978\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "start = time.time()\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=10)\n",
    "model_selu.fit(x_train_standardized, y_train, epochs=100,\n",
    "              validation_data=(x_valid_standardized, y_valid),\n",
    "              callbacks=[early_stopping, model_cp])\n",
    "end = time.time()\n",
    "print(\"Time taken for training the model_selu: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a45a785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 925us/step - loss: 1.4906 - accuracy: 0.4896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4906381368637085, 0.4896000027656555]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_cifar10_model.h5\")\n",
    "model.evaluate(x_valid_standardized, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c9f61c",
   "metadata": {},
   "source": [
    "### e) Alpha dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16d4396c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_alpha_dropout = model_selu = keras.models.Sequential([keras.layers.Flatten(input_shape=(32, 32, 3)),\n",
    "                                                            keras.layers.AlphaDropout(rate=0.2),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                                            keras.layers.AlphaDropout(rate=0.2),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                                            keras.layers.AlphaDropout(rate=0.2),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                                            keras.layers.AlphaDropout(rate=0.2),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                                            keras.layers.AlphaDropout(rate=0.2),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                                            keras.layers.AlphaDropout(rate=0.2),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                                            keras.layers.AlphaDropout(rate=0.2),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                                            keras.layers.AlphaDropout(rate=0.2),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                                            keras.layers.AlphaDropout(rate=0.2),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                                            keras.layers.AlphaDropout(rate=0.2),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                                            keras.layers.AlphaDropout(rate=0.2),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                                            keras.layers.AlphaDropout(rate=0.2),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                                            keras.layers.AlphaDropout(rate=0.2),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                                            keras.layers.AlphaDropout(rate=0.2),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                                            keras.layers.AlphaDropout(rate=0.2),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                                            keras.layers.AlphaDropout(rate=0.2),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                                            keras.layers.AlphaDropout(rate=0.2),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                                            keras.layers.AlphaDropout(rate=0.2),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                                            keras.layers.AlphaDropout(rate=0.2),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                                            keras.layers.AlphaDropout(rate=0.2),\n",
    "                                keras.layers.Dense(units=100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "                                                            keras.layers.AlphaDropout(rate=0.2),\n",
    "                                keras.layers.Dense(units=10, activation=\"softmax\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eca37b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_alpha_dropout.compile(loss = \"sparse_categorical_crossentropy\",\n",
    "                            optimizer = \"nadam\",\n",
    "                            metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ac54c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 9s 4ms/step - loss: 2.2930 - accuracy: 0.1466 - val_loss: 178.8407 - val_accuracy: 0.1392\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 2.0669 - accuracy: 0.1852 - val_loss: 120.5056 - val_accuracy: 0.1428\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 2.0544 - accuracy: 0.1920 - val_loss: 73.8143 - val_accuracy: 0.1240\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 2.0269 - accuracy: 0.2089 - val_loss: 111.7378 - val_accuracy: 0.1220\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 2.0265 - accuracy: 0.2131 - val_loss: 80.2081 - val_accuracy: 0.1486\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 2.0187 - accuracy: 0.2230 - val_loss: 93.5622 - val_accuracy: 0.1972\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 2.0100 - accuracy: 0.2356 - val_loss: 101.9291 - val_accuracy: 0.1958\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 2.0011 - accuracy: 0.2409 - val_loss: 45.5646 - val_accuracy: 0.1944\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 1.9651 - accuracy: 0.2490 - val_loss: 45.9960 - val_accuracy: 0.1430\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 1.9554 - accuracy: 0.2521 - val_loss: 39.2645 - val_accuracy: 0.1994\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 1.9552 - accuracy: 0.2541 - val_loss: 57.3512 - val_accuracy: 0.2016\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 1.9498 - accuracy: 0.2531 - val_loss: 50.8336 - val_accuracy: 0.2040\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 1.9816 - accuracy: 0.2522 - val_loss: 68.5524 - val_accuracy: 0.2038\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 2.0342 - accuracy: 0.2317 - val_loss: 69.7143 - val_accuracy: 0.1032\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 2.0797 - accuracy: 0.2045 - val_loss: 31.0773 - val_accuracy: 0.1158\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 2.0369 - accuracy: 0.2262 - val_loss: 46.5019 - val_accuracy: 0.1402\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 2.0506 - accuracy: 0.2197 - val_loss: 109.6740 - val_accuracy: 0.1732\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 2.0182 - accuracy: 0.2286 - val_loss: 38.1762 - val_accuracy: 0.1368\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 2.0277 - accuracy: 0.2247 - val_loss: 81.9204 - val_accuracy: 0.1452\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 2.0395 - accuracy: 0.2190 - val_loss: 122.7669 - val_accuracy: 0.1518\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 2.0477 - accuracy: 0.2152 - val_loss: 73.9589 - val_accuracy: 0.1380\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 2.0128 - accuracy: 0.2230 - val_loss: 81.5981 - val_accuracy: 0.1608\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 1.9928 - accuracy: 0.2302 - val_loss: 76.9342 - val_accuracy: 0.1124\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 2.0117 - accuracy: 0.2267 - val_loss: 51.2998 - val_accuracy: 0.1554\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 1.9960 - accuracy: 0.2372 - val_loss: 60.0472 - val_accuracy: 0.1714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd0f03029b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time taken to train model_AD:  125.67989873886108\n"
     ]
    }
   ],
   "source": [
    "start_AD = time.time()\n",
    "model_alpha_dropout.fit(x_train_standardized, y_train, epochs=100,\n",
    "                       validation_data=(x_valid_standardized, y_valid),\n",
    "                       callbacks=[early_stopping, model_cp])\n",
    "end_AD = time.time()\n",
    "print(\"The time taken to train model_AD: \", end_AD-start_AD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cf4a5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 977us/step - loss: 60.0472 - accuracy: 0.1714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[60.04716873168945, 0.17139999568462372]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_cifar10_model.h5\")\n",
    "model.evaluate(x_valid_standardized, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd28efd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_probas = np.stack([model_alpha_dropout(x_valid_standardized, training=True)\n",
    "                     for sample in range(100)])\n",
    "\n",
    "y_probas = y_probas.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48b4f76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(model_alpha_dropout.predict(x_valid_standardized[:1]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "342379fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02, 0.02, 0.15, 0.08, 0.23, 0.11, 0.23, 0.15, 0.01, 0.01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_probas[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5062dcb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02, 0.02, 0.15, ..., 0.15, 0.01, 0.01],\n",
       "       [0.12, 0.29, 0.03, ..., 0.04, 0.17, 0.23],\n",
       "       [0.02, 0.01, 0.17, ..., 0.13, 0.01, 0.01],\n",
       "       ...,\n",
       "       [0.17, 0.21, 0.04, ..., 0.04, 0.25, 0.18],\n",
       "       [0.3 , 0.08, 0.06, ..., 0.02, 0.39, 0.08],\n",
       "       [0.05, 0.08, 0.1 , ..., 0.18, 0.04, 0.06]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_probas[:], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5eb0a7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2714"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(y_probas, axis = 1)\n",
    "\n",
    "y_pred = y_pred.reshape(y_valid.shape)\n",
    "\n",
    "accuracy = np.sum(y_pred == y_valid) / len(y_valid)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d8ec85",
   "metadata": {},
   "source": [
    "### f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13d8bccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_rate, start_rate=None, last_iteration=None, last_rate=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate / 10\n",
    "        self.last_iterations = last_iteration or iterations //10+1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or self.start_rate / 1000\n",
    "        self.iteration = 0\n",
    "        \n",
    "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "        return ((rate2-rate1) * (self.iteration-iter1) / (iter2-iter1) + rate1)\n",
    "    \n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                     self.max_rate, self.start_rate)\n",
    "        else:\n",
    "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                     self.start_rate, self.last_rate)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.learning_rate, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a15d2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6e39dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "352/352 [==============================] - 1s 4ms/step - loss: 2.2573 - accuracy: 0.1875 - val_loss: 2.3330 - val_accuracy: 0.0970\n",
      "Epoch 2/25\n",
      "352/352 [==============================] - 1s 4ms/step - loss: 35.8995 - accuracy: 0.0996 - val_loss: 6.5997 - val_accuracy: 0.1064\n",
      "Epoch 3/25\n",
      "352/352 [==============================] - 1s 4ms/step - loss: 4.1982 - accuracy: 0.0996 - val_loss: 2.4267 - val_accuracy: 0.0970\n",
      "Epoch 4/25\n",
      "352/352 [==============================] - 1s 4ms/step - loss: 357225920.0000 - accuracy: 0.0998 - val_loss: 29.8931 - val_accuracy: 0.0958\n",
      "Epoch 5/25\n",
      "352/352 [==============================] - 1s 4ms/step - loss: 17134095695872.0000 - accuracy: 0.1003 - val_loss: 38.4913 - val_accuracy: 0.0958\n",
      "Epoch 6/25\n",
      "352/352 [==============================] - 1s 4ms/step - loss: 89721866813440.0000 - accuracy: 0.0977 - val_loss: 22.3636 - val_accuracy: 0.0950\n",
      "Epoch 7/25\n",
      "352/352 [==============================] - 1s 4ms/step - loss: 6040175104.0000 - accuracy: 0.1001 - val_loss: 17.8636 - val_accuracy: 0.0950\n",
      "Epoch 8/25\n",
      "352/352 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.1022 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 9/25\n",
      "352/352 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 10/25\n",
      "352/352 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
      "Epoch 11/25\n",
      "352/352 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.1002 - val_loss: nan - val_accuracy: 0.0986\n",
      "The time taken to train model_alpha_dropout using onecycle learning scheduler:  15.474812746047974\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 25\n",
    "batch_size = 128\n",
    "onecycle = OneCycleScheduler(iterations = (math.ceil(len(x_train)/batch_size) * n_epochs), max_rate = 0.05)\n",
    "start_1cy = time.time()\n",
    "history = model_alpha_dropout.fit(x_train_standardized, y_train, epochs=n_epochs, batch_size=batch_size, \n",
    "                             validation_data=(x_valid_standardized, y_valid),\n",
    "                             callbacks=[onecycle, early_stopping, model_cp])\n",
    "end_1cy = time.time()\n",
    "print(\"The time taken to train model_alpha_dropout using onecycle learning scheduler: \", end_1cy-start_1cy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d991907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 852us/step - loss: nan - accuracy: 0.0986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, 0.09860000014305115]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_cifar10_model.h5\")\n",
    "model.evaluate(x_valid_standardized, y_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
